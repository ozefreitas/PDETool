configfile: "config/config.yaml"

rule all:
	input:
		"Data/HMMs/HMMsearch_results/After_UPI/{threshold}/{cluster}.out"


rule UPIMAPI_search:
	input:
		sequence="workflow/Data/FASTA/literature_seq/lit_sequences.fasta",
		database="workflow/Data/FASTA/DataBases/familiesDB.fasta"
	output:
		"workflow/Alignments/BLAST/results/upimapi_results/UPIMAPI_results.tsv"
	params:
		outdir="workflow/Alignments/BLAST/results/upimapi_results"
	threads: 8
	log:
		"logs/UPIMAPI_search.log"
	conda:
		"envs/"
	shell:
		"upimapi.py -i {input.sequence} -o {params.outdir} -db {input.database} -t {threads}"


rule UPIMAPI_parse:
	input:
		"workflow/Alignments/BLAST/results/upimapi_results/UPIMAPI_results.tsv"
	output:
		"workflow/Data/Tables/UPIMAPI_results_per_sim.tsv"
	conda:
		"envs/"
	script:
		"scripts/UPIMAPI_parser.py"


wildcard_constraints:
    threshold="[0-9 \-]+"
	cluster="[0-9]+"


rule seq_download:
# esta fica dependente da proxima regra, ou seja, so corre quando se pede a initial_cdhit_per_threshold
	input:
		"workflow/Data/Tables/UPIMAPI_results_per_sim.tsv"
	output:
		"workflow/Data/FASTA/UPIMAPI/{threshold}.fasta"  # terá que fazer os ficheiros para todos os thresholds de uma só vez
	script:
		"scripts/seq_download.py"


rule initial_cdhit_per_threshold:
	input:
		"workflow/Data/FASTA/UPIMAPI/{threshold}.fasta"  # é o output da regra anterior com wildcards
	output:
		"workflow/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta",
		"workflow/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta.clstr"
		# expand("workflow/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta", threshold=config["thresholds"])  # sem .clstr porque ele ja vai fazer os dois ficheiros
	shell:
		"cd-hit -i data/{input} -o {output} -c 0.9 -n 5 -M 16000 -d 0 -T 8"


rule cdhit_parse:
	input:
		"workflow/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta.clstr"
	output:
		"workflow/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv"
	script:
		"scripts/CDHIT_parser.py"


#rule mockup:
#	input:
#		expand("workflow/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv", threshold=config["thresholds"])
#	output:
#		"mockup.out"
#	run:
#		with open("mockup.out") as f:
#			f.write("sucess!")
#



rule seq_download_cdhit:
	input:
		"workflow/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv"
	output:
		"workflow/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta"  # um ficheiro por cada cluster, por threshold, com as sequencias
	script:
		"scripts/CDHIT_seq_download.py" # from_cdhit


rule mockup:
	input:
		expand("workflow/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta", threshold=config["thresholds"], cluster=config[clusters])
	output:
		"mockup.out"
	run:
		with open("mockup.out") as f:
			f.write("sucess!")

from glob import glob

files = {threshold: glob(f"workflow/Data/FASTA/CDHIT/{threshold}/*.fasta") for threshold in config["thresholds"]}
threshold2clusters = {k : [v.split("/")[-1].split('.f')[0] for v in values] for k, values in files.items()}


rule t_coffee:
	input:
	 	"Data/FASTA/CDHIT/{threshold}/{cluster}.fasta"
	output:
		"Alignments/MultipleSequencesAlign/T_Coffee_UPI/{threshold}/{cluster}.clustal_aln"
	shell:
		"t_coffee data/{input} -run_name data/{output} -output clustalw_aln"


rule hmmbuild:
	input:
		"Alignments/MultipleSequencesAlign/T_Coffee_UPI/{thresholds}/{cluster}.clustal_aln"
	output:
		"Data/HMMs/After_tcoffee_UPI/{threshold}/{cluster}.hmm"
	shell:
		"hmmbuild {output} {input}"


rule hmmsearch:
	input:
		"Data/HMMs/After_tcoffee_UPI/{threshold}/{cluster}.hmm",
		"path to DB"
	output:
		"Data/HMMs/HMMsearch_results/After_UPI/{threshold}/{cluster}.out"
	shell:
		"hmmsearch {input} > {output}"