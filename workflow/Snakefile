configfile: "config/config.yaml"

rule all:
	input:
		"Data/HMMs/HMMsearch_results/After_UPI/{threshold}/{cluster}.out"


rule UPIMAPI_search:
	input:
		sequence="workflow/Data/FASTA/literature_seq/lit_sequences.fasta",
		database="workflow/Data/FASTA/DataBases/familiesDB.fasta"
	output:
		"workflow/Alignments/BLAST/results/upimapi_results/UPIMAPI_results.tsv"
	params:
		outdir="workflow/Alignments/BLAST/results/upimapi_results"
	threads: 8
	log:
		"logs/UPIMAPI_search.log"
	conda:
		"envs/"
	shell:
		"upimapi.py -i {input.sequence} -o {params.outdir} -db {input.database} -t {threads}"


rule UPIMAPI_parse:
	input:
		"workflow/Alignments/BLAST/results/upimapi_results/UPIMAPI_results.tsv"
	output:
		"workflow/Data/Tables/UPIMAPI_results_per_sim.tsv"
	conda:
		"envs/"
	script:
		"scripts/UPIMAPI_parser.py"


wildcard_constraints:
    threshold="[0-9 \-]+",
	cluster="[0-9]+"


rule seq_download:
# esta fica dependente da proxima regra, ou seja, so corre quando se pede a initial_cdhit_per_threshold
	input:
		"workflow/Data/Tables/UPIMAPI_results_per_sim.tsv"
	output:
		"workflow/Data/FASTA/UPIMAPI/{threshold}.fasta"  # terá que fazer os ficheiros para todos os thresholds de uma só vez
	script:
		"scripts/seq_download.py"


rule initial_cdhit_per_threshold:
	input:
		"workflow/Data/FASTA/UPIMAPI/{threshold}.fasta"  # é o output da regra anterior com wildcards
	output:
		"workflow/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta",
		"workflow/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta.clstr"
		# expand("workflow/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta", threshold=config["thresholds"])  # sem .clstr porque ele ja vai fazer os dois ficheiros
	shell:
		"cd-hit -i {input} -o {output} -c 0.9 -n 5 -M 16000 -d 0 -T 8"


rule cdhit_parse:
	input:
		"workflow/Data/FASTA/UPIMAPI/cd-hit90_after_diamond_{threshold}.fasta.clstr"
	output:
		"workflow/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv"
	script:
		"scripts/CDHIT_parser.py"


# junta num dicionário os thresholds com os clusters correspondentes
from scripts.CDHIT_parser import get_clusters
from glob import glob
# vai buscar aos .tsv criados antes, e não fica dependente dos fasta que vão ser criados
files = {threshold: glob(f"workflow/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv") for threshold in config["thresholds"]}
threshold2clusters = {}
for thresh, path in files.items():
	threshold2clusters[thresh] = get_clusters(path[0])

# fazer uma lista de listas com todos os clusters, por ordem de threshold
big_list_clusters = [v for k, v in threshold2clusters.items()]


# rule mockup:
# 	input:
# 		expand("workflow/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv", threshold=config["thresholds"])
# 	output:
# 		"mockup.out"
# 	run:
# 		with open("mockup.out") as f:
# 			f.write("sucess!")


# função vai fazer todas as combinações entre thresholds e clusters correspondentes
def util(lista_thresholds, lista_de_listas_clusters):
	for threshold in range(len(lista_thresholds)):
		for cluster in lista_de_listas_clusters[threshold]:
			combinacao = (lista_thresholds[threshold], cluster)
			yield combinacao


# função que vai buscar os clusters correspondentes a cada threshold
def match_threshold_W_cluster(combinador) -> tuple:
	def match_threshold_W_cluster(*args, **kwargs):
		for combo in combinador(*args, **kwargs):
			yield combo
	return match_threshold_W_cluster


# inicializar função de combinação
thresh_clust_combinations = match_threshold_W_cluster(util)


rule seq_download_cdhit:
	input:
		"workflow/Data/Tables/cdhit_clusters_{threshold}_afterUPIMAPI.tsv"
	output:
		# um ficheiro por cada cluster, por threshold, com as sequencias
		"workflow/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta"
		# expand("workflow/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta", thresh_clust_combinations, threshold=config["thresholds"], cluster = big_list_clusters)
	script:
		"scripts/CDHIT_seq_download.py" # from_cdhit


# files = {threshold: glob(f"workflow/Data/FASTA/CDHIT/{threshold}/*.fasta") for threshold in config["thresholds"]}
# threshold2clusters = {k : [v.split("/")[-1].split('.f')[0] for v in values] for k, values in files.items()}


rule mockup:
	input:
		expand("workflow/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta", thresh_clust_combinations, threshold=config["thresholds"], cluster=big_list_clusters)
	output:
		"mockup.out"
	run:
		with open("mockup.out") as f:
			f.write("sucess!")


rule t_coffee:
	input:
	 	"workflow/Data/FASTA/CDHIT/{threshold}/{cluster}.fasta"
	output:
		"workflow/Alignments/MultipleSequencesAlign/T_Coffee_UPI/{threshold}/{cluster}.clustal_aln"
	shell:
		"t_coffee {input} -run_name {output} -output clustalw_aln"


rule hmmbuild:
	input:
		"workflow/Alignments/MultipleSequencesAlign/T_Coffee_UPI/{thresholds}/{cluster}.clustal_aln"
	output:
		"workflow/Data/HMMs/After_tcoffee_UPI/{threshold}/{cluster}.hmm"
	shell:
		"hmmbuild {output} {input}"


rule hmmsearch:
	input:
		hmms = "workflow/Data/HMMs/After_tcoffee_UPI/{threshold}/{cluster}.hmm",
		database = "path to DB"
	output:
		"workflow/Data/HMMs/HMMsearch_results/After_UPI/{threshold}/{cluster}.out"
	shell:
		"hmmsearch {input.hmms} {input.database} > {output}"